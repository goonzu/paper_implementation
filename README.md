# paper_implementation

# Reference
코드들은 일반적으로 opensource 를 참고하여 만들었으며,
출처는 이곳에 정의됩니다.

## paper_implementation/NLP/Attention is all you need
https://github.com/bentrevett/pytorch-seq2seq/
https://github.com/spro/practical-pytorch
https://github.com/keon/seq2seq
https://github.com/pengshuang/CNN-Seq2Seq
https://github.com/pytorch/fairseq
https://github.com/jadore801120/attention-is-all-you-need-pytorch
http://nlp.seas.harvard.edu/2018/04/03/attention.html
https://www.analyticsvidhya.com/blog/2019/06/understanding-transformers-nlp-state-of-the-art-models/
